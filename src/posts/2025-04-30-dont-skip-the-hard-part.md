---
layout: post
title: >
  ðŸ¦¿ AI Adoption: The Cost of Skipping the Hard Part
---

<!-- summary -->

**Competence in the Age of AI**

Leadership in legacy organisations may impose AI to speed up delivery in the short term.
As developers, we need think beyond this alluring elixir. To preserve our hard-won skills in good design and intentionality in how we scale our systems to retain human agency over them.

<!-- /summary -->

Adoption of LLMs in software teams, especially at non-tech-native firms has been tentative; even suspect. Some [mandating](https://leaddev.com/culture/ai-coding-mandates-are-driving-developers-to-the-brink) and even stack-ranking its people on adoption into workflows, in a panicked attempt to keep up and leverage â€˜productivityâ€™ gain possible _for the business._ As I wrote previously, a more meaningful, intentional value of AI exists beyond quicker output of the wrong thing. What is it to be _productive_ if teams are still _ineffective?_

Indeed, the one thing we know about the thing we _are_ building, is that _it is wrong._ Our goal as builders of useful software, is to find out _where_, and how we can make it _less wrong_ as soon and as often as possible. All the agile ceremonies, words and artefacts are mere performance, if they do not assist us in that endeavour.

In agile, the only measure of progress, is _working software_.

Meanwhile, as Product Engineers, many rightly view AI contribution to the codebase with skepticism.

My experience has been that the _fitness_ of AI-generated code in the first place diminishes the less proximal the problem space is. AI is not well suited to the long term maintainability.

Given that the [cost of software is roughly equivalent to the cost of change](https://www.youtube.com/watch?v=ZHpQs46xizQ) (Kent Beck), we must insist we retain _optionality_ in our software design; something AI is presently and in my very experience _bad at._ Unless we know how to guard against it, we risk enabling AI to takn our codebases and Products with spiralling costs of change.

**Getting from 0-60**

That said, AI can, and _does_ alleviate much toil in *rote code generation; u*pgrading libraries, prototypes, releases, suggesting bug sources, maybe even writing tests.

It gets us from â€˜_0-60â€™_ much quicker, allowing a technical Product team to quickly _pilot a hypothesis_ and get real, early feedback; data with which to decide the bets worth pursing, at the expense of something else.

Because thatâ€™s what weâ€™re doing with Products: making a bet; a hypothesis and testing it often, and AI allows us to tighten that cycle.

If we do not, as organisations, competitors will. The baseline of being able to quickly learn and iterate has increased for all of us.

Businesses are obligated then, to _enable_ their people and optimise for learning and iteration. But this also means the _manner in which_ they chose adopt AI in support of an existing competitive advantage is existentially important.

Coercing developers into adoption by mandating its use feels an out-of-touch and short-sighted move, implying a lack of trust that developers wouldnâ€™t naturally adopt tools that _help them_ of their own accord. If they choose not to - at least in the ways org leaders _understand_ AI to be beneficial - thatâ€™s a liberty of onesâ€™ own professional judgement.

Mandated AI intervention in our workflows exposes teams to second order effects; not just in skill atrophy and our own existential risk, but the myriad ways in which AI introduces wrong solutions, arbitrary tech choices and coupling into the code, as recounted [in this dispatch](https://martinfowler.com/articles/exploring-gen-ai/13-role-of-developer-skills.html) from Martin Fowlersâ€™ blog; evaluating an LLMâ€™s impact on dev skills.

**Devs against entropy**

We must guard against our own hard-learned skills becoming undermined; in knowing what good, changeable, decoupled software design looks like and needs to be preserved, especially in organisations who obsess over mere productivity and overlook the value of good design.

A team losing its grasp on changeability is a team losing agency. On a long enough timeline, thatâ€™s how a product dies.

We need to protect the tacit knowledge that underpins our systemsâ€”the know-how, the judgment, the sense of design. Not just to be productive long-term, but to remain authors of our productsâ€™ user experience.

**Its fun to be competent**

There are no shortcuts to becoming _competent_ at software design, and this will become even more, not less, crucial for working effectively with AI. We are now responsible Lead devs to the AI. We risk relegating much of our time to reviewing its output, and protecting the codebase from the chaos it enables, until the organisation is fully weaned off humans all-together.

Therefore, as engineers we have responsibility _to ourselves_ and the continued development of our skills and relevance as creators, \*\*to not become dependant.

If we allow ourselves to become dependant, we are _choosing_ learned helplessness, not â€˜_being efficient.â€™_

Real productivity starts with intentionality; consider what we _want_ a solution to look like first before using the assistant.

**The siren call of autocomplete**

Are we _in this moment_ making a conscious decision to forego learning? Will we or our colleagues need to pay that up or make sense of this? If so, are we happy with that cost?

Itâ€™s been personally rattling to notice this creeping in; reflexively _expecting_ a solution to (often incorrectly), and having to be very diligent to notice this temptress.

We may need to hold nerve for just a moment, against the background noise of urgency.

We must remember in that choice point: organisationsâ€™ goals are impersonal: to maximise productivity and efficiency by any means necessary. This is fine; itâ€™s in their DNA and is their responsibility.

But we as creators have a choice. Responsibility to ourselves; to be the _guardians_ of our enduring competence in safeguarding our technical fitness personally.

**It is fun to be competent, and there are no shortcuts.**

Productivity matters, but only when have _earned_ the ability through the _yards_ in software development, _maintenance,_ and deep understanding of good design, to _decide_ when to accept AI our workflow to truly enhance our productivity and abilities, not replace our judgement.
